{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb89fac-f991-4868-bec4-9d64fbebdbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n",
      "Точность на тестовых данных (метод градиентного спуска): 0.9920\n",
      "Точность на тестовых данных (метод подкрепления): 0.9020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=10):\n",
    "        \"\"\"\n",
    "        Инициализация параметров персептрона.\n",
    "\n",
    "        :param input_size: количество входных признаков\n",
    "        :param learning_rate: скорость обучения (alpha)\n",
    "        :param epochs: количество эпох обучения\n",
    "        \"\"\"\n",
    "        # Инициализация весов\n",
    "        self.weights = np.random.randn(input_size + 1)  # Добавляем bias\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def activation_function(self, x):\n",
    "        \"\"\"\n",
    "        Функция активации — сигмоид.\n",
    "        Преобразует входное значение в диапазон (0,1).\n",
    "\n",
    "        :param x: входное значение (сумма взвешенных входов)\n",
    "        :return: выходное значение после применения сигмоидной функции\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Из-за ошибки RuntimeWarning: overflow encountered in exp return 1 / (1 + np.exp(-x))  # Сигмоидная функция\n",
    "        связаной с тем, что значения, которые попадают в экспоненциальную функцию np.exp(-x), \n",
    "        могут быть слишком большими или слишком маленькими, что приводит к переполнению (overflow). \n",
    "        Это может происходить, если сумма взвешенных входов (линейная комбинация) слишком велика по абсолютной величине.\n",
    "        \"\"\"\n",
    "        # Ограничиваем значения x, чтобы избежать переполнения\n",
    "        x = np.clip(x, -700, 700)  # Значения для функции exp не должны быть слишком большими\n",
    "        return 1 / (1 + np.exp(-x))  # Сигмоидная функция\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вычисляет предсказания модели.\n",
    "\n",
    "        :param X: входные данные (матрица признаков)\n",
    "        :return: массив предсказанных значений (вероятности)\n",
    "        \"\"\"\n",
    "        # Добавляем столбец из единиц к X для учета bias\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        # Вычисляем сумму взвешенных входов и применяем активационную функцию\n",
    "        return self.activation_function(np.dot(X, self.weights))\n",
    "\n",
    "    def train(self, X, y, method='gradient_descent'):\n",
    "        \"\"\"\n",
    "        Обучает модель методом градиентного спуска или методом подкрепления.\n",
    "\n",
    "        :param X: матрица признаков (размер N x M)\n",
    "        :param y: вектор целевых значений (размер N)\n",
    "        :param method: метод обучения ('gradient_descent' или 'reinforcement')\n",
    "        \"\"\"\n",
    "        \n",
    "        # Добавляем столбец из единиц к X для учета bias\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        for epoch in range(self.epochs):  # Цикл по эпохам\n",
    "            for i in range(X.shape[0]):  # Проход по каждому объекту\n",
    "                # Вычисляем линейную комбинацию входов и весов\n",
    "                z = np.dot(X[i], self.weights)\n",
    "                # Применяем функцию активации\n",
    "                y_pred = self.activation_function(z)\n",
    "                # Вычисляем ошибку\n",
    "                error = y[i] - y_pred\n",
    "\n",
    "                if method == 'gradient_descent':\n",
    "                    # Градиентный спуск: обновляем веса с учетом ошибки\n",
    "                    self.weights += self.lr * error * X[i]\n",
    "                \n",
    "                elif method == 'reinforcement':\n",
    "                    # Метод подкрепления: обновление в зависимости от ошибки\n",
    "                    if error > 0:\n",
    "                        # Положительное подкрепление: увеличиваем веса\n",
    "                        self.weights += self.lr * X[i]\n",
    "                    elif error < 0:\n",
    "                        # Отрицательное подкрепление: уменьшаем веса\n",
    "                        self.weights -= self.lr * X[i]\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Метод обучения не поддерживается. Выберите 'gradient_descent' или 'reinforcement'.\")\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        Оценивает точность модели.\n",
    "\n",
    "        :param X: тестовые входные данные\n",
    "        :param y: реальные метки классов\n",
    "        :return: точность классификации\n",
    "        \"\"\"\n",
    "        # Получаем предсказания модели\n",
    "        predictions = self.predict(X)\n",
    "        # Преобразуем вероятности в бинарные классы (0 или 1)\n",
    "        predictions = (predictions >= 0.5).astype(int)\n",
    "        # Сравниваем предсказания с реальными метками\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy\n",
    "\n",
    "# Загрузка данных MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразуем изображения в одномерные векторы (28x28 = 784)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype(np.float32)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype(np.float32)\n",
    "\n",
    "# Нормализуем данные\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Преобразуем метки в бинарные (для двух классов, например 0 и 1)\n",
    "y_train = (y_train == 0).astype(int)  # Пример для классификации только 0 и 1\n",
    "y_test = (y_test == 0).astype(int)\n",
    "\n",
    "# Создание и обучение персептрона с методом градиентного спуска\n",
    "perceptron = Perceptron(input_size=784, learning_rate=0.1, epochs=10)\n",
    "perceptron.train(x_train, y_train, method='gradient_descent')\n",
    "\n",
    "# Оценка точности на тестовых данных после обучения методом градиентного спуска\n",
    "accuracy = perceptron.evaluate(x_test, y_test)\n",
    "print(f\"Точность на тестовых данных (метод градиентного спуска): {accuracy:.4f}\")\n",
    "\n",
    "# Создание и обучение персептрона с методом подкрепления\n",
    "perceptron = Perceptron(input_size=784, learning_rate=0.1, epochs=10)\n",
    "perceptron.train(x_train, y_train, method='reinforcement')\n",
    "\n",
    "# Оценка точности на тестовых данных после обучения методом подкрепления\n",
    "accuracy = perceptron.evaluate(x_test, y_test)\n",
    "print(f\"Точность на тестовых данных (метод подкрепления): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde3553-af2f-4a05-b5df-afe1f8442142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
